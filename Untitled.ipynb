{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "590b6432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "269576"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('Rabindranath.txt','r',encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2aa61af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Rabindranath Tagore\\n- poems -\\n\\n\\n\\n\\nPublication Date:\\n 2012\\nPublisher:\\nPoemhunter.com - The World's Po\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d9b5fab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c74c873d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, 51, 52, 59, 64, 54, 68, 51, 64, 51, 70, 58, 1, 44, 51, 57, 65, 68, 55]\n",
      "Rabindranath Tagore\n"
     ]
    }
   ],
   "source": [
    "str2int = {ch:i for i,ch in enumerate(chars)}\n",
    "int2str = {i:ch for i,ch in enumerate(chars)}\n",
    "encode = lambda s:[str2int[c] for c in s]\n",
    "decode = lambda l:''.join([int2str[n] for n in l])\n",
    "\n",
    "e = encode('Rabindranath Tagore')\n",
    "print(e)\n",
    "d = decode(e)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "488ef29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([269576])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([42, 51, 52, 59, 64, 54, 68, 51, 64, 51, 70, 58,  1, 44, 51, 57, 65, 68,\n",
       "        55,  0, 10,  1, 66, 65, 55, 63, 69,  1, 10,  0,  0,  0,  0,  0, 40, 71,\n",
       "        52, 62, 59, 53, 51, 70, 59, 65, 64,  1, 28, 51, 70, 55, 22,  0,  1, 14,\n",
       "        12, 13, 14,  0, 40, 71, 52, 62, 59, 69, 58, 55, 68, 22,  0, 40, 65, 55,\n",
       "        63, 58, 71, 64, 70, 55, 68, 11, 53, 65, 63,  1, 10,  1, 44, 58, 55,  1,\n",
       "        47, 65, 68, 62, 54,  6, 69,  1, 40, 65])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.tensor(encode(text),dtype=torch.long)\n",
    "print(data.shape)\n",
    "data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "245832fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd34582a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([42, 51, 52, 59, 64, 54, 68, 51, 64])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0ab41431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when context is tensor([42]) then target: 51\n",
      "when context is tensor([42, 51]) then target: 52\n",
      "when context is tensor([42, 51, 52]) then target: 59\n",
      "when context is tensor([42, 51, 52, 59]) then target: 64\n",
      "when context is tensor([42, 51, 52, 59, 64]) then target: 54\n",
      "when context is tensor([42, 51, 52, 59, 64, 54]) then target: 68\n",
      "when context is tensor([42, 51, 52, 59, 64, 54, 68]) then target: 51\n",
      "when context is tensor([42, 51, 52, 59, 64, 54, 68, 51]) then target: 64\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f'when context is {context} then target: {target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "23ba1dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 8]), torch.Size([4, 8]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(7)\n",
    "batch_size = 4 # size of parallel batches of block_size (batch_dimension)\n",
    "block_size = 8 # size of chunk of data we process (time_dimension)\n",
    "\n",
    "def get_batch(split):\n",
    "    # to get random chunk of data for each training or validation\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    idx = torch.randint(len(data)-block_size-1,(batch_size,))\n",
    "    x = torch.stack([data[i:block_size+i] for i in idx])\n",
    "    y = torch.stack([data[i+1:block_size+i+1] for i in idx])\n",
    "    return x,y\n",
    "\n",
    "xb,yb = get_batch('train')\n",
    "xb.shape,yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cefea44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{tensor([51]): tensor(72)}\n",
      "{tensor([51, 72]): tensor(55)}\n",
      "{tensor([51, 72, 55]): tensor(1)}\n",
      "{tensor([51, 72, 55,  1]): tensor(70)}\n",
      "{tensor([51, 72, 55,  1, 70]): tensor(58)}\n",
      "{tensor([51, 72, 55,  1, 70, 58]): tensor(55)}\n",
      "{tensor([51, 72, 55,  1, 70, 58, 55]): tensor(0)}\n",
      "{tensor([51, 72, 55,  1, 70, 58, 55,  0]): tensor(69)}\n",
      "{tensor([51]): tensor(64)}\n",
      "{tensor([51, 64]): tensor(54)}\n",
      "{tensor([51, 64, 54]): tensor(69)}\n",
      "{tensor([51, 64, 54, 69]): tensor(1)}\n",
      "{tensor([51, 64, 54, 69,  1]): tensor(73)}\n",
      "{tensor([51, 64, 54, 69,  1, 73]): tensor(58)}\n",
      "{tensor([51, 64, 54, 69,  1, 73, 58]): tensor(65)}\n",
      "{tensor([51, 64, 54, 69,  1, 73, 58, 65]): tensor(1)}\n",
      "{tensor([54]): tensor(65)}\n",
      "{tensor([54, 65]): tensor(73)}\n",
      "{tensor([54, 65, 73]): tensor(64)}\n",
      "{tensor([54, 65, 73, 64]): tensor(1)}\n",
      "{tensor([54, 65, 73, 64,  1]): tensor(71)}\n",
      "{tensor([54, 65, 73, 64,  1, 71]): tensor(66)}\n",
      "{tensor([54, 65, 73, 64,  1, 71, 66]): tensor(65)}\n",
      "{tensor([54, 65, 73, 64,  1, 71, 66, 65]): tensor(64)}\n",
      "{tensor([1]): tensor(31)}\n",
      "{tensor([ 1, 31]): tensor(51)}\n",
      "{tensor([ 1, 31, 51]): tensor(68)}\n",
      "{tensor([ 1, 31, 51, 68]): tensor(54)}\n",
      "{tensor([ 1, 31, 51, 68, 54]): tensor(55)}\n",
      "{tensor([ 1, 31, 51, 68, 54, 55]): tensor(64)}\n",
      "{tensor([ 1, 31, 51, 68, 54, 55, 64]): tensor(55)}\n",
      "{tensor([ 1, 31, 51, 68, 54, 55, 64, 55]): tensor(68)}\n"
     ]
    }
   ],
   "source": [
    "for b in range(batch_size): # (batch_dimension)\n",
    "    for t in range(block_size): # (time_dimension)\n",
    "        context = xb[b,:t+1]\n",
    "        target = yb[b,t]\n",
    "        print({context:target})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adc5621",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d5831f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 84])\n",
      "tensor(5.1176, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 101])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n3NyOGn7rE !6v?e8(H7–06…7D19:Hdnz—3vVF4Pb“VErS1–JCivF—4 6b’FOV”qcvo\"vi!ayhVGn`”h\"TU\\nQ“o“roVB1o\\'VyK&NQ'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(7)\n",
    "\n",
    "class BigramModel(nn.Module):\n",
    "    def __init__(self,vocab_size):\n",
    "        super().__init__()\n",
    "        # lookup table for tokens\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size,vocab_size)\n",
    "        \n",
    "    def forward(self,idx,target=None):\n",
    "        # for each index in idx it reutrns token rows\n",
    "        logits = self.token_embedding_table(idx) # return (B,T,C) (Batch,Time,Channel)\n",
    "        if target is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B,T,C = logits.shape\n",
    "            logits = logits.view(B*T,C) # since cross_entropy accept differnt dime of input (B,C,T)\n",
    "            target = target.view(B*T)\n",
    "            loss = F.cross_entropy(logits,target)\n",
    "        return logits,loss\n",
    "\n",
    "    def generate(self,idx,max_tokens):\n",
    "        for _ in range(max_tokens):\n",
    "            logits,loss = self.forward(idx) # getting predictions\n",
    "             # taking only the last idx prediction --> (B,C)\n",
    "            logits = logits[:,-1,:] # (B,C)\n",
    "            # softing for get probabilities\n",
    "            probs = F.softmax(logits,dim=-1) # (B,C)\n",
    "            # get one sample index from given probabilities and add to end of idx\n",
    "            sample_idx = torch.multinomial(probs,num_samples=1)\n",
    "            idx = torch.cat((idx,sample_idx),dim=1) # (B,T+1)\n",
    "        return idx\n",
    "    \n",
    "m = BigramModel(vocab_size)\n",
    "logits, loss = m(xb,yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "\n",
    "# sample text to test the model\n",
    "input_idx = torch.zeros((1,1), dtype = torch.long)\n",
    "# generated tokens of length 100\n",
    "g_idx = m.generate(input_idx,100)\n",
    "\n",
    "print(g_idx.shape)\n",
    "decode(g_idx[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ab88ba0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of BigramModel(\n",
      "  (token_embedding_table): Embedding(84, 84)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "print(m.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "99a8a4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch optimizer model AdamW\n",
    "optimizer = torch.optim.AdamW(m.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8322d821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.430452585220337\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for _ in range(1000):\n",
    "    xb,yb = get_batch('train')\n",
    "    logits, loss = m(xb,yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "65c86be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 301])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nakenky ve. tindy edrthee\\n P\\n town bl tr lead.\\nWanglenndepiof wind t thee ten\\n o o ts?\\n bbrofin Th aye g spt s af a ben y bld usto ovaghord howe s Lousld here blllowed gin.\\nF a's ckearn bs T fingle,\\nI ather irof my to oot itrs atedees g we wame herar s woned t:My wart noy ary m\\nTary tanat uth t tht a\""
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample text to test the model\n",
    "input_idx = torch.zeros((1,1), dtype = torch.long)\n",
    "# generated tokens of length 100\n",
    "g_idx = m.generate(input_idx,300)\n",
    "\n",
    "print(g_idx.shape)\n",
    "decode(g_idx[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb11853f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanogpt",
   "language": "python",
   "name": "nanogpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
